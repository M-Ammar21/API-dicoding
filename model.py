# -*- coding: utf-8 -*-
"""Final_Course _Content Filtering.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xvJxN5iIQgKVo1kQzcWY-8_6zwxiN7uT
"""

# !pip install -q Sastrawi
import json
import os
import sys
from dotenv import load_dotenv
import pandas as pd
import re
from pymongo import MongoClient
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory
# from google.colab import drive

# drive.mount('/content/Drive')

# df_courses = pd.read_csv('/content/Drive/MyDrive/Data/courses.csv', names = ["course name", "course description", "tags", "register_cnt"])

load_dotenv()

mongodb_uri = os.getenv("MONGODB_URI")
client = MongoClient(mongodb_uri)
db = client['capstone']

collection = db['courses-rev2']

data = collection.find({}, {"course name": 1, "course description": 1, "tags": 1, "register_cnt": 1})

df_courses = pd.DataFrame(data)

def clean_text(input) :
  html = r"<.*?>"
  symb = r'[\/(){}\[\]\|@,;]'

  text = re.sub(html, ' ', input)
  text = re.sub(symb, ' ', text)
  return ' '.join(text.split())

df_courses['course description'] = df_courses['course description'].apply(clean_text)
df_courses['tags'] = df_courses['tags'].apply(clean_text)
df_courses['soup'] = df_courses['course name'] + ' ' + df_courses['course description'] + ' ' + df_courses['tags']

stopword_factory = StopWordRemoverFactory()
stopwords_indo = stopword_factory.get_stop_words()
indices = pd.Series(df_courses['course name'])

count = CountVectorizer(stop_words = stopwords_indo)
count_matrix = count.fit_transform(df_courses['soup'])
cosine_sim_count = cosine_similarity(count_matrix, count_matrix)

def get_recommendations(jobs, n):
    if find_job_name(jobs) == None :
      return "Maaf, belum ada course yang sesuai"
    idx = indices[indices == find_job_name(jobs)].index[0]
    sim_scores = list(enumerate(cosine_sim_count[idx]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
    sim_scores = sim_scores[0:n]

    jobs_indices = [i[0] for i in sim_scores]
    jobs_scores = [i[1] for i in sim_scores]

    recommended_jobs = df_courses['course name'].iloc[jobs_indices]

    return list(zip(recommended_jobs, jobs_scores))

def find_job_name(raw):
  filtered = list(indices)
  for word in raw.lower().split() :
    filtered = [title for title in filtered if word in title.lower()]
    if not filtered :
      return None
  return filtered[0]

if __name__ == "__main__":
    jobs = sys.argv[1]
    n = int(sys.argv[2])
    recommendations = get_recommendations(jobs, n)
    print(json.dumps(recommendations))

#recommendations with count
#parameter:
# jobs : input to find the similar jobs
# n : Top n recommendations to give
# get_recommendations('javascript', 5)